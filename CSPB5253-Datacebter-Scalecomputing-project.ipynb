{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of a Distributed Image Classifier to Separate Useful from Useless Images in Crystallographic Experiments\n",
    "#### Author: Sabine Hollatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background - The Research Context\n",
    "This project is part of my internship at the National Accelerator Laboratory SLAC with\n",
    "the Molecular Crystallography group.\n",
    "When protein molecules are in crystallized form and are shot with x-rays, their\n",
    "detected diffraction pattern can provide insight to the molecular structure of a single\n",
    "protein molecule. [The following image was provided by Luigi Nardi](https://dawn.cs.stanford.edu/2019/04/23/deepfreak/)<img src=\"./demo-images/crystallography_example.png\"> <br>This is how many protein, RNA, and DNA structures were\n",
    "discovered such as lysozyme or the zika virus shell. When a molecular structure is\n",
    "discovered, the proteins functionality can be understood and, in case of pathogens,\n",
    "medication can be developed. The video below provides a brief overview of the way the experiments are conducted. Crystallographic experiments are currently deducted\n",
    "with the recent coronavirus 2 (SARS-CoV-2). [More information to Covid-19 research at SLAC](https://www.iucr.org/news/newsletter/volume-28/number-2/ssrl-joins-global-fight-against-covid-19)<br>\n",
    "Machine Learning is requested, because current detectors can take thousands of\n",
    "images per second, so that a pre-screening for quality by the human eye is not\n",
    "feasible anymore. A machine learning model could give useful feedback about the\n",
    "potential success or failure of an experiment in real time. This is particularly useful in\n",
    "serial crystallography, where proteins are used that are difficult to crystallize, so that\n",
    "the protein sample size is small. Therefore the number of useful images is small as\n",
    "well, but the number of total images is large.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/mYz3KEDQDwQ\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f8fe00b0610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('mYz3KEDQDwQ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background - The Data\n",
    "Even though diffraction images are all grayscale images that show white dots on a\n",
    "circular background, they can be quite different and are unique for each molecular\n",
    "structure. To provide an idea of diffraction images in general, I selected the following\n",
    "6 images (please zoom into each image to see the differences clearly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>Images without Diffraction (blank or no crystal)<tr><td><img width='250' src='demo-images/blank.png'></td><td><img width='200' src='demo-images/fake_20815_noxtal.png'></td><td><img width='200' src='demo-images/fake_20801_blank_withairscatter.png'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "display(HTML(\"<table>Images without Diffraction (blank or no crystal)<tr><td><img width='250' src='demo-images/blank.png'></td><td><img width='200' src='demo-images/fake_20815_noxtal.png'></td><td><img width='200' src='demo-images/fake_20801_blank_withairscatter.png'></td></tr></table>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>Diffraction Images<tr><td>weak diffraction<img width='220' src='demo-images/fake_20848_weak.png'></td><td>good diffraction<img width='220' src='demo-images/fake_20811_good.png'></td><td>strong diffraction<img width='220' src='demo-images/fake_20838_strong.png'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<table>Diffraction Images<tr><td>weak diffraction<img width='220' src='demo-images/fake_20848_weak.png'></td><td>good diffraction<img width='220' src='demo-images/fake_20811_good.png'></td><td>strong diffraction<img width='220' src='demo-images/fake_20838_strong.png'></td></tr></table>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Goals\n",
    "I have set up a scalable, distributed system that classifies diffraction images from\n",
    "crystallographic experiments into two categories: images that can provide valuable\n",
    "information (show diffraction) and images that are useless to the researcher (no\n",
    "diffraction). In the future I will optimize the throughput and enable more convenient query methods to the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Architecture\n",
    "<img src=\"project-finalArchitecture.png\" alt=\"Final Project Architecture\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>The entry to the application is provided by an ingress to a REST API interface</li>\n",
    "    <li>Message queues enable the communication between the entry REST API interface, the worker server, the redis databases and the logging service.</li>\n",
    "    <li>Storage for image hashes, filenames and prediction results is provided in a redis database</li>\n",
    "<li>The entire application is organized in a Minikube Cluster using Kubernetes and Docker containers. That way  transportability and scalability are enabled.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used Technologies\n",
    "The application is written in Python and uses the following libraries: codecs, flask, hashlib, io, json, jsonpickle, numpy, os, pickle, pika, Pillow, platform, redis, requests, sys, time.\n",
    "Kubernetes is used with Docker Containers on a local Minikube cluster. Pods are managed by deployments and services in form of yaml files. Networking between pods is enabled through services, environmental variables and an internal dns service provided by Kubernetes. The entry is given by an ingress which provides a public IP address. Test images are stored in a bucket on Google Cloud. The REST API interface manages and forwards the incoming client requests through a RabbitMQ brokered communication system to the workers as well as to the database and the logging system. The deep learning classifier was previously trained and saved in H5 format. To serve the model in a production environment, it is stored in a pb format and added to a tensorflow serving docker container. The prediction request to the tensorflow serving model uses HTTP. The image filename, image hash, and the prediction results are stored in 3 redis databases, so that the integrity of the image files can be ensured without the overload of storing the image files themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Steps in Creating and Running the Application\n",
    "These steps need to be performed from command line and not in a jupyter notebook. For this reason they are shown as text instead of executable code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting the minikube cluster"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "minikube start\n",
    "minikube addons configure registry-creds\n",
    "# https://index.docker.io/v1/\n",
    "minikube addons enable ingress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Tensorflow Serving Docker Image\n",
    "The model was saved in the Hierarchical Data Format H5, which contains multidimensional arrays of scientific data, but needs to become a tensorflow pb format in order to be used with tensorflow serving. A model saved in pb format contains the complete graph, including weights and computation. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"./model/vgg16_diff-nodiff_classification.h5\")\n",
    "tf.keras.models.save_model(model, \"./model/1/vgg16_diff-nodiff_classification.pb\", save_format=\"tf\")\n",
    "# directory '1' was added because tensorflow serving expects a version specification at that point."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker pull tensorflow/serving\n",
    "docker run -d --name serving_base tensorflow/serving\n",
    "docker cp ../model/vgg16_diff-nodiff_classification.pb serving_base:/models/vgg16_diff-nodiff_classification.pb\n",
    "docker commit --change \"ENV MODEL_NAME vgg16_diff-nodiff_classification.pb\" serving_base vgg16_diff-nodiff_classifier\n",
    "\n",
    "# pushing to docker hub\n",
    "docker tag d7bb33b5297e shollatz/vgg16_diff-nodiff_classifier:v1\n",
    "docker push shollatz/vgg16_diff-nodiff_classifier:v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting Kubernete Pods, Deployments, Services and the Ingress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f redis/redis-deployment.yaml\n",
    "kubectl apply -f redis/redis-service.yaml\n",
    "kubectl apply -f rabbitmq/rabbitmq-deployment.yaml\n",
    "kubectl apply -f rabbitmq/rabbitmq-service.yaml\n",
    "kubectl apply -f worker/tfserving-deployment.yaml\n",
    "kubectl apply -f worker/tfserving-service.yaml\n",
    "kubectl apply -f worker/worker-deployment.yaml\n",
    "kubectl apply -f rest/rest-deployment.yaml\n",
    "kubectl apply -f rest/rest-service.yaml\n",
    "kubectl apply -f rest/logs-deployment.yaml\n",
    "kubectl apply -f rest/rest-ingress.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Run Shown in Demo Video\n",
    "To show changes in the database I have written a python script that can be executed interactivly inside the pod with the container ml-worker. I am going to execute it once before to show that the database is empty and once after a curl command is executed. The sample images are stored in a bucket on Google Cloud."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kubectl exec --stdin --tty <worker-deployment-pod> /bin/sh\n",
    "# run inside the pod:\n",
    "python3 redis-list.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kubectl describe ingress frontend-ingress"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "REST = 192.168.49.2\n",
    "curl -d '{\"url\":\"https://storage.googleapis.com/csci4253_project_images/fake_20804.png\"}' -H \"Content-Type: application/json\" -X POST http://$REST/scan/url"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kubectl exec --stdin --tty <worker-deployment-pod> /bin/sh\n",
    "# run inside the pod:\n",
    "python3 redis-list.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging and Testing\n",
    "I used logging to provide information from every executing node in the system as well as error reporting. The service application was tested first with a few images both from a local file system as well as from a given url. The architecture was built component by component and debugged at every step along the way. It was ensured that the image information can be reproduced after\n",
    "scanning and storing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of Component Choices and Future Improvements\n",
    "Due to time contraints, I could create a minimal viable product, in which all components can communicate with each other to provide the overall functionality of a remote, distributed, scalabel image classifier for diffraction images. Data integrety is provided by the brokered RabbitMQ communication system and stored image hashes in the redis database. However, throughput is an important component that will be optimized in the future. Currently, the incoming communication and the communication between the worker and the tensorflow serving model is following REST and HTTP. gRCP is faster and can be optimized to machine learning with TFRecords.\n",
    "Furthermore, there will be a choice provided between sending single images and sending images in batches. These two adjustments will enhance the throughput that will be measured with benchmark tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
